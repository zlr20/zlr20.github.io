---
title: Python并行编程(1)基本概念
date: 2020-12-09 18:06:51
tags:
- Python
categories:
- Python
---

本文将介绍一些并行编程的架构和编程模型。对于初次接触并行编程技术的程序员来说，这些都是非常有用的概念；对于经验丰富的程序员来说，本章可以作为基础参考。

<!--More-->

解决一个大问题的一般方法是，将其拆分成若干小的、独立的问题，然后分别解它们。并行的程序也是使用这种方法，用多个处理器同时工作，来完成同一个任务。特点是：

- 每一个处理器都做自己的那部分独立的工作。
- 计算过程中处理器之间可能需要交换数据。

如今，软件应用或算法要求越来越高的计算能力。提高计算能力有两种思路：提高处理器的时钟速度或增加芯片上的核心数。提高时钟速度就必然会增加散热，然后每瓦特的性能就会降低，甚至可能要求特殊的冷却设备。提高芯片的核心数是更可行的一种方案，因为能源的消耗和散热，第一种方法必然有上限，而且计算能力提高没有特别明显。为了解决这个问题，计算机硬件供应商的选择是多核心的架构，就是在同一个芯片上放两个或者多个处理器（核心）。GPU制造商也逐渐引进了这种基于多处理器核心的硬件架构。事实上，今天的计算机几乎都是各种多核、异构的计算单元组成的，每一个单元都有多个处理核心。所以，对我们来说充分利用计算资源就显得至关重要，例如并行计算的程序、技术和工具等。

# 1. 并行计算的内存架构

根据指令的同时执行和数据的同时执行，计算机系统可以分成以下四类：

- 单指令，单数据 (SISD)
- 单指令，多数据 (SIMD)
- 多指令，单数据 (MISD)
- 多指令，多数据 (MIMD)

这种分类方法叫做“费林分类”:

<img src='https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/flynn.png' width=600>

## 1.1 SISD-操作系统课本中的体系

单处理器单数据就是“单CPU的机器”，它在单一的数据流上执行指令。在SISD中，指令被顺序地执行。

对于每一个“CPU时钟”，CPU按照下面的顺序执行：

- **Fetch**: CPU 从一片内存区域中（寄存器）获得数据和指令
- **Decode**: CPU对指令进行解码
- **Execute**: 该执行在数据上执行，将结果保存在另一个寄存器中

当Execute阶段完成之后，CPU回到步骤1准备执行下一个时钟循环。

<img src="https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/SISD-schema.png" width=600>

运行在这些计算机上的算法是顺序执行的（连续的），不存在任何并行。只有一个CPU的硬件系统就是SISD的例子。

这种架构（冯·诺依曼体系）的主要元素有以下：

- 中心内存单元：存储指令和数据
- CPU：用于从内存单元获得指令/数据，对指令解码并顺序执行它们
- I/O系统：程序的输入和输出流

传统的单处理器计算机都是经典的SISD系统。

## 1.2 MISD-抽象模型、不实用

这种模型中，有n个处理器，每一个都有自己的控制单元，共享同一个内存单元。在每一个CPU时钟中，从内存获得的数据会被所有的处理器同时处理，每一个处理器按照自己的控制单元发送的指令处理。在这种情况下，并行实际上是指令层面的并行，多个指令在相同的数据上操作。能够合理利用这种架构的问题模型比较特殊，例如数据加密等。因此，MISD在现实中并没有很多用武之地，更多的是作为一个抽象模型的存在。

<img src="https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/MISD.png" width=600>

## 1.3 SIMD-GPU的并行模式

SIMD计算机包括多个独立的处理器，每一个都有自己的局部内存，可以用来存储数据。所有的处理器都在单一指令流下工作；具体说，就是有n个数据流，每个处理器处理一个。所有的处理器同时处理每一步，在不同的数据上执行相同的指令。这是一个数据并行的例子。SIMD架构比MISD架构要实用的多。很多问题都可以用SIMD计算机的架构来解决。这种架构另一个有趣的特性是，这种架构的算法非常好设计，分析和实现。限制是，只有可以被分解成很多个小问题（小问题之间要独立，可以不分先后顺序被相同的指令执行）的问题才可以用这种架构解决。很多超级计算机就是使用这架构设计出来的。例如Connection Machine（1985年的 Thinking Machine)和MPP（NASA-1983）。在现代图形处理器（GPU）中就内置了很多个SIMD处理单元，使这种架构在今天应用非常广泛。

## 1.4 MIMD-功能最完整的并行模式

在费林分类中，这种计算机是最广泛使用、也是最强大的一个种类。这种架构有n个处理器，n个指令流，n个数据流。每一个处理器都有自己的控制单元和局部内存，让MIMD架构比SIMD架构的计算能力更强。每一个处理器都在独立的控制单元分配的指令流下工作；因此，处理器可以在不同的数据上运行不同的程序，这样可以解决完全不同的子问题甚至是单一的大问题。在MIMD中，架构是通过线程或进程层面的并行来实现的，这也意味着处理器一般是异步工作的。这种类型的计算机通常用来解决那些没有统一结构、无法用SIMD来解决的问题。如今，很多计算机都应用了这中间架构，例如超级计算机，计算机网络等。然而，有一个问题不得不考虑：异步的算法非常难设计、分析和实现。

<img src="https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/MIMD.png" width=600>

# 2. 内存管理

内存管理（确切来说是获得数据的方式）是并行架构需要考虑的另一方面重要内容。无论CPU多快，如果内存提供指令和数据的速度跟不上，系统性能也不会得到提升。制约内存达到处理器速度级别的响应时间的主要因素是内存存取周期。所谓存取周期就是连续启动两次读或写操作所需间隔的最小时间。处理器的周期通常比内存周期短得多。当处理器传送数据到内存或从内存中获取数据时，内存依旧在一个周期中，其他任何设备（I/O控制器，处理器）都不能使用内存，因为内存必须先对上一个请求作出响应。

<img src="https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/Page-7-Image-1.png" width=600>

为了解决 MIMD 架构访问内存的问题，业界提出了两种内存管理系统。第一种是**共享内存系统**。共享内存系统有大量的虚拟内存空间，而且各个处理器对内存中的数据和指令拥有平等的访问权限。另外一种类型是**分布式内存模型**，在这种内存模型中，每个处理器都有自己专属的内存，其他处理器都不能访问。

共享内存和分布式内存的区别以处理器的角度来说就是内存和虚拟内存体系的不同。每个系统的内存都会分为能独立访问的不同部分。共享内存系统和分布式内存系统的处理单元管理内存访问的方式也不相同。 `load R0,i` 指令意味着将 `i` 内存单元的内容加载进 `R0` 寄存器，但内存管理方式的不同，处理器的处理方式也不尽相同。在共享内存的系统中， `i` 代表的是内存的全局地址，对系统中的所有处理器来说都指向同一块内存空间。如果两个处理器想同时执行该内存中的指令，它们会向 `R0` 寄存器载入相同的内容。在分布式内存系统中， `i` 是局部地址。如果两个处理器同时执行向 `R0` 载入内容的语句，执行结束之后，不同处理器 `R0` 寄存器中的值一般情况下是不一样的，因为每个处理器对应的内存单元中的 `i` 代表的全局地址不一样。

对于程序员来说，必须准确的区分共享内存和分布式内存，因为在并行编程中需要考量内存管理方式来决定进程或线程间通讯的方式。对于共享内存系统来说，共享内存能够在内存中构建数据结构并在子进程间通过引用直接访问该数据结构。而对于分布式内存系统来说，必须在每个局部内存保存共享数据的副本。一个处理器会向其他处理器发送含有共享数据的消息从而创建数据副本。这使得分布式内存管理有一个显而易见的缺点，那就是，如果要发送的消息太大，发送过程会耗费相对较长的时间。

## 2.1 共享内存

下图展示了共享内存多处理器系统的架构，这里只展示了各部件之间简单的物理连接。总线结构允许任意数量的设备共享一个通道。总线协议最初设计是让单处理器，一个或多个磁盘和磁带控制器通过共享内存进行通讯。可以注意到处理器拥有各自的Cache，Cache中保存着局部内存中有可能被处理器使用的指令或数据。可以想象一下，当一个处理器修改了内存中的数据，同时另外一个处理器正在使用这个数据时，就会出现问题。已修改的值会从处理器的Cache传递到共享内存中，接着，新值会传递到其他处理器的Cache中，其它处理器就不可以使用旧值进行计算。这就是人们所熟知的Cache一致性问题，是内存一致性问题的一种特殊情况，要解决这个问题需要硬件能像多进程编程一样实现处理并发问题和同步控制 。

<img src="https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/Page-8-Image-1.png" width=600>

共享内存系统的主要特性如下：

- 内存对于所有处理器来说是一样的，例如，所有处理器所对应的相同数据结构都存在于相同的逻辑地址，也就是说可以从相同的内存单元中获得该数据结构。
- 通过控制处理器对共享内存的访问权限可以达到同步控制的效果。实际上，每次只有一个处理器拥有对内存资源的访问权限。
- 当一个任务正在访问共享内存的时候，其它所有任务都不能改变内存单元的内容。
- 共享内存很快，两个任务通讯的时间和读取单个内存单元的时间相等（取决于内存的访问速度）

## 2.2 分布式内存

在使用分布式内存的系统中，各个处理器都有其各自的内存，而且每个处理器只能处理属于自己的内存。某些学者把这类系统称为“多计算机系统”，这个名字很真实地反映了组成这类系统的元素能够独立作为一个具有内存和处理器的微型系统，如下图所示：

<img src="https://python-parallel-programmning-cookbook.readthedocs.io/zh_CN/latest/_images/Page-10-Image-1.png" width=600>

这种内存管理方式有几个好处。第一，总线和开关级别的的通讯不会发生冲突。每个处理器都可以无视其他处理器的干扰而充分利用局部内存的带宽；第二，没有通用总线意味着没有处理器数量的限制，系统的规模只局限于连接处理器的网络带宽；第三，没有Cache一致性问题的困扰。每个处理器只需要处理属于自己的数据而无须关心上传数据副本的问题。但最大的缺点是，很难实现处理器之间的通讯。如果一个处理器需要其他处理器的数据，这两个处理器必须要通过消息传递协议来交换消息。这样进行通讯会导致速度降低，原因有两个，首先，从一个处理器创建和发送消息到另外一个处理器需要时间；其次，任何处理器都需要停止工作，处理来自其他处理器的消息。面向分布式内存机器的程序必须按照尽量相互独立的任务来组织，任务之间通过消息进行通讯。

分布式内存系统的特性如下：

- 内存通常分布在不同的处理器之中，局部内存只能由对应的处理器访问。
- 同步控制通过在处理器之间转移数据 (也可以是消息本身) 来实现， 同理通讯的实现方式也一样。
- 局部内存的数据分支会影响机器的性能——有必要精确地进行数据分割最小化 CPU 间的通讯。另外，协调数据的分解合成操作的处理器必须与处理部分数据的处理器高效地通讯。
- 消息传递协议用于 CPU 间通过交换数据包通讯。消息是信息的分解单元，他们经过良好的定义，所以处理器之间能够准确地识别出消息地内容。

# 3. 并行程序设计

并行算法的设计是基于一系列操作的，在编程的过程中必须执行这些操作来准确地完成工作而不会产生部分结果或错误结果。并行算法地大致操作如下：

- 任务分解 (Task decomposition)
- 任务分配 (Task assignment)
- 聚合 (Agglomeration)
- 映射 (Mapping)

## 3.1 任务分解

第一阶段，将软件程序分解为可以在不同处理器执行的多个任务或一系列指令以实现并行性。下面展示了两个方法来实现程序分解：

- 按范围分解 (Domain decomposition)：使用这个分解方法，程序所需的数据会被分解；处理器会使用同一个程序处理不同的数据。这个方法一般在需要处理大量数据的情况下使用。
- 按功能分解 (Functional decomposition)：使用这个分解方法会将问题分解为几个任务，每个任务会对可利用的数据执行不同的操作。

## 3.2 任务分配

在这个步骤中，并行程序将任务分配给各种处理器的机制是确定的。这个阶段非常重要，因为在这阶段会向各个处理器之间分配工作。负载均衡是这个阶段的关键，所有处理器都应该保持工作状态，避免长时间的空闲。为了实现这个效果，程序员必须考虑异构系统的可能性，异构系统会尝试将任务分配给相对更适合的处理器。最后，为了让并行程序有更高的效率，必须尽量减少处理器之间的通讯，因为处理器之间的通讯通常是程序变慢和资源消耗的源头。

## 3.3 聚合

聚合，就是为了提升性能将小任务合并成大任务的过程。如果设计过程的前两个阶段是将分解问题得到的任务数量大大超过处理器可接受的程度，或者计算机不是专门设计用于处理大量小任务 (如GPU的架构就非常适合处理数百万甚至上亿任务)，那么过分解会导致严重的效率下降。一般情况下，这是因为任务需要跟处理它的处理器或线程进行通讯。大多数的通讯的消耗不仅包括跟传输数据量相称的部分，还包括进行通讯的固定部分 (如建立 TCP 连接的延迟)。如果分解的任务过小，固定消耗可能比数据量还大，可以说这样的设计是低效的。

## 3.4 映射

在并行算法设计的映射阶段，会指定任务由哪个处理器处理。这阶段的目标是减少总体的执行时间。在这里需要经常做取舍，因为下面两个相互矛盾的策略：

- 需要频繁通讯的任务应该由同一个处理器处理以增强局部性。
- 可以并行执行的任务应该由多个处理器处理以增强并行性。

这就是所谓的映射问题，也是一个NP完全问题——一般情况下不能再多项式时间内解决的问题。在大小相等和通讯模式容易定义的任务中，映射很直接 (在这里也可以执行聚合的步骤来合并映射到相同处理器的任务)。但是如果任务的通讯模式难以预测或者每个任务的工作量都不一样，设计一个高效的映射和聚合架构就会变得有难度。由于存在这些问题，负载均衡算法会在运行时识别聚合和映射策略。最难的问题是在程序执行期间通信量或任务数量改变的问题。针对这些问题，可以使用在执行过程中周期性运行的动态负载均衡算法。

## 3.5 动态映射

无论是全局还是局部，对于不同的问题都有不同的负载均衡算法。全局算法需要对即将指向的计算有全局的认识，这样通常会增加很多开销。局部算法只需要依靠正在解决的问题的局部信息，对比全局算法能够减少很多开销，但在寻找最佳聚合和映射的能力较差。然而，即使映射的结果较差，节省的开销一般还是能减少执行时间。如果任务除了执行开始和结束几乎不和其它任务进行通讯，那么可以使用任务调度算法简单地把任务分配给空转的处理器。在任务调度算法中，会维护一个任务池，任务池中包含了待执行的任务，工作单元 (一般是处理器) 会从中取出任务执行。

# 4. 线程与进程

进程是应用程序的一个执行实例，比如，在桌面上双击浏览器图标将会运行一个浏览器。线程是一个控制流程，可以在进程内与其他活跃的线程同时执行。“控制流程”指的是顺序执行一些机器指令。进程可以包含多个线程，所以开启一个浏览器，操作系统将创建一个进程，并开始执行这个进程的主线程。每一个线程将独立执行一系列的指令（通常就是一个函数），并且和其他线程并行执行。然而，同一个进程内的线程可以共享一些地址空间和数据结构。线程也被称作“轻量进程”，因为它和进程有许多共同点，比如都是可以和其他控制流程同时运行的控制流程，说它“轻量”是因为实现一个进程比线程要繁重的多。重申一遍，不同于进程，多个线程可以共享很多资源，特别是地址空间和数据结构等。

总结一下：

- 进程可以包含多个并行运行的线程。
- 通常，操作系统创建和管理线程比进程更能节省CPU的资源。线程用于一些小任务，进程用于繁重的任务——运行应用程序。
- 同一个进程下的线程共享地址空间和其他资源，进程之间相互独立。